{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13717937,"sourceType":"datasetVersion","datasetId":8727419},{"sourceId":13733781,"sourceType":"datasetVersion","datasetId":8737946},{"sourceId":13738937,"sourceType":"datasetVersion","datasetId":8727560},{"sourceId":13736109,"sourceType":"datasetVersion","datasetId":8739933},{"sourceId":13738727,"sourceType":"datasetVersion","datasetId":8741573}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!gdown --id 1GQIXgCSF3Usiuy5hkxgOl483RPX3f_SX -O language.pt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-15T04:55:52.938219Z","iopub.execute_input":"2025-11-15T04:55:52.938519Z","iopub.status.idle":"2025-11-15T04:56:03.859472Z","shell.execute_reply.started":"2025-11-15T04:55:52.938498Z","shell.execute_reply":"2025-11-15T04:56:03.858691Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1GQIXgCSF3Usiuy5hkxgOl483RPX3f_SX\nFrom (redirected): https://drive.google.com/uc?id=1GQIXgCSF3Usiuy5hkxgOl483RPX3f_SX&confirm=t&uuid=29e27f30-ba70-4870-b7d5-d611f94a635f\nTo: /kaggle/working/language.pt\n100%|████████████████████████████████████████| 436M/436M [00:07<00:00, 55.1MB/s]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!python /kaggle/input/utils-code/split_dataset.py --metadata_path /kaggle/input/fluencybank-dataset/FluencyBank/metadata.csv --train_ratio 0.8 --test_ratio 0.10 --val_ratio 0.10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T20:00:39.530998Z","iopub.execute_input":"2025-11-14T20:00:39.531197Z","iopub.status.idle":"2025-11-14T20:00:41.586324Z","shell.execute_reply.started":"2025-11-14T20:00:39.531179Z","shell.execute_reply":"2025-11-14T20:00:41.585314Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python /kaggle/input/test-code/test.py --metadata_path /kaggle/input/dataset-split/test_metadata.csv \\\n    --word_dir /kaggle/input/fluencybank-dataset/FluencyBank/csvs/csvs \\\n    --weights_path /kaggle/working/language.pt \\\n    --batch_size 16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T05:04:24.568123Z","iopub.execute_input":"2025-11-15T05:04:24.568811Z","iopub.status.idle":"2025-11-15T05:04:43.712386Z","shell.execute_reply.started":"2025-11-15T05:04:24.568775Z","shell.execute_reply":"2025-11-15T05:04:43.711421Z"}},"outputs":[{"name":"stdout","text":"2025-11-15 05:04:30.387325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763183070.409928     126 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763183070.416853     126 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nLoading weights from: /kaggle/working/language.pt\nEvaluating: 100%|███████████████████████████████| 23/23 [00:04<00:00,  5.65it/s]\n\n=== Evaluation Results ===\nAverage BCEWithLogits loss: 0.0605\n\nFP: precision=0.9726, recall=1.0000, f1=0.9861, support_pos=142\nRP: precision=0.9545, recall=0.5833, f1=0.7241, support_pos=396\nRV: precision=0.3197, recall=0.6258, f1=0.4232, support_pos=163\nRS: precision=0.0000, recall=0.0000, f1=0.0000, support_pos=0\nPW: precision=0.8000, recall=0.7926, f1=0.7963, support_pos=217\nND: precision=0.9821, recall=0.9739, f1=0.9780, support_pos=4331\n\nMacro averages (5 disfluencies + ND):\n  macro recall = 0.6626\n  macro F1     = 0.6513\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train(\n        train_metadata_path='/kaggle/input/dataset-split/train_metadata.csv',\n        val_metadata_path='/kaggle/input/dataset-split/val_metadata.csv',\n        word_dir='/kaggle/input/fluencybank-dataset/FluencyBank/csvs/csvs',\n        output_weights='/kaggle/working/language_fluencybank.pt',\n        init_weights='/kaggle/working/language.pt',\n        batch_size=16,\n        lr=5e-5,\n        epochs=20,\n        max_length=256,\n        threshold=0.5,\n        device='cuda',\n        segid_column=\"segid\",\n        eval_every=100,\n        patience_evals=10,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T05:32:37.895682Z","iopub.execute_input":"2025-11-15T05:32:37.896036Z","iopub.status.idle":"2025-11-15T05:49:10.096687Z","shell.execute_reply.started":"2025-11-15T05:32:37.896011Z","shell.execute_reply":"2025-11-15T05:49:10.095934Z"}},"outputs":[{"name":"stdout","text":"Training examples: 2710 (steps/epoch = 170, batch_size = 16)\nValidation examples: 358\nEval every 100 steps, patience 10 evals.\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Loading weights from: /kaggle/working/language.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 [train]:  58%|█████▊    | 99/170 [00:52<00:37,  1.90it/s, loss=0.0376]\nval @ step 100:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 100:   4%|▍         | 1/23 [00:00<00:05,  3.77it/s]\u001b[A\nval @ step 100:   9%|▊         | 2/23 [00:00<00:05,  3.79it/s]\u001b[A\nval @ step 100:  13%|█▎        | 3/23 [00:00<00:05,  3.78it/s]\u001b[A\nval @ step 100:  17%|█▋        | 4/23 [00:01<00:05,  3.72it/s]\u001b[A\nval @ step 100:  22%|██▏       | 5/23 [00:01<00:04,  3.72it/s]\u001b[A\nval @ step 100:  26%|██▌       | 6/23 [00:01<00:04,  3.68it/s]\u001b[A\nval @ step 100:  30%|███       | 7/23 [00:01<00:04,  3.62it/s]\u001b[A\nval @ step 100:  35%|███▍      | 8/23 [00:02<00:04,  3.64it/s]\u001b[A\nval @ step 100:  39%|███▉      | 9/23 [00:02<00:05,  2.65it/s]\u001b[A\nval @ step 100:  43%|████▎     | 10/23 [00:03<00:04,  2.92it/s]\u001b[A\nval @ step 100:  48%|████▊     | 11/23 [00:03<00:03,  3.11it/s]\u001b[A\nval @ step 100:  52%|█████▏    | 12/23 [00:03<00:03,  3.26it/s]\u001b[A\nval @ step 100:  57%|█████▋    | 13/23 [00:03<00:02,  3.38it/s]\u001b[A\nval @ step 100:  61%|██████    | 14/23 [00:04<00:02,  3.48it/s]\u001b[A\nval @ step 100:  65%|██████▌   | 15/23 [00:04<00:02,  3.45it/s]\u001b[A\nval @ step 100:  70%|██████▉   | 16/23 [00:04<00:01,  3.53it/s]\u001b[A\nval @ step 100:  74%|███████▍  | 17/23 [00:04<00:01,  3.58it/s]\u001b[A\nval @ step 100:  78%|███████▊  | 18/23 [00:05<00:01,  3.59it/s]\u001b[A\nval @ step 100:  83%|████████▎ | 19/23 [00:05<00:01,  3.62it/s]\u001b[A\nval @ step 100:  87%|████████▋ | 20/23 [00:05<00:00,  3.62it/s]\u001b[A\nval @ step 100:  91%|█████████▏| 21/23 [00:06<00:00,  3.65it/s]\u001b[A\nval @ step 100:  96%|█████████▌| 22/23 [00:06<00:00,  3.65it/s]\u001b[A\nval @ step 100: 100%|██████████| 23/23 [00:06<00:00,  3.57it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"\nStep 100: val_loss = 0.0252, val_UAR = 0.5775\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 [train]:  59%|█████▉    | 100/170 [00:59<03:06,  2.66s/it, loss=0.0376]","output_type":"stream"},{"name":"stdout","text":"  -> New best model (step 100) saved to /kaggle/working/language_fluencybank.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 [train]: 100%|██████████| 170/170 [01:33<00:00,  1.82it/s, loss=0.0349]\nEpoch 2 [train]:  17%|█▋        | 29/170 [00:14<01:06,  2.11it/s, loss=0.0189]\nval @ step 200:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 200:   4%|▍         | 1/23 [00:00<00:03,  5.95it/s]\u001b[A\nval @ step 200:   9%|▊         | 2/23 [00:00<00:03,  5.96it/s]\u001b[A\nval @ step 200:  13%|█▎        | 3/23 [00:00<00:03,  6.00it/s]\u001b[A\nval @ step 200:  17%|█▋        | 4/23 [00:00<00:03,  5.96it/s]\u001b[A\nval @ step 200:  22%|██▏       | 5/23 [00:00<00:03,  5.77it/s]\u001b[A\nval @ step 200:  26%|██▌       | 6/23 [00:01<00:02,  5.77it/s]\u001b[A\nval @ step 200:  30%|███       | 7/23 [00:01<00:02,  5.47it/s]\u001b[A\nval @ step 200:  35%|███▍      | 8/23 [00:01<00:02,  5.66it/s]\u001b[A\nval @ step 200:  39%|███▉      | 9/23 [00:01<00:02,  5.79it/s]\u001b[A\nval @ step 200:  43%|████▎     | 10/23 [00:01<00:02,  5.91it/s]\u001b[A\nval @ step 200:  48%|████▊     | 11/23 [00:01<00:02,  5.92it/s]\u001b[A\nval @ step 200:  52%|█████▏    | 12/23 [00:02<00:01,  6.01it/s]\u001b[A\nval @ step 200:  57%|█████▋    | 13/23 [00:02<00:01,  6.05it/s]\u001b[A\nval @ step 200:  61%|██████    | 14/23 [00:02<00:01,  6.13it/s]\u001b[A\nval @ step 200:  65%|██████▌   | 15/23 [00:02<00:01,  6.14it/s]\u001b[A\nval @ step 200:  70%|██████▉   | 16/23 [00:02<00:01,  6.12it/s]\u001b[A\nval @ step 200:  74%|███████▍  | 17/23 [00:02<00:01,  5.58it/s]\u001b[A\nval @ step 200:  78%|███████▊  | 18/23 [00:03<00:00,  5.74it/s]\u001b[A\nval @ step 200:  83%|████████▎ | 19/23 [00:03<00:00,  5.84it/s]\u001b[A\nval @ step 200:  87%|████████▋ | 20/23 [00:03<00:00,  5.91it/s]\u001b[A\nval @ step 200:  91%|█████████▏| 21/23 [00:03<00:00,  5.98it/s]\u001b[A\nval @ step 200: 100%|██████████| 23/23 [00:03<00:00,  6.06it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"\nStep 200: val_loss = 0.0252, val_UAR = 0.6526\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [train]:  18%|█▊        | 30/170 [00:19<04:31,  1.94s/it, loss=0.0189]","output_type":"stream"},{"name":"stdout","text":"  -> New best model (step 200) saved to /kaggle/working/language_fluencybank.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [train]:  76%|███████▌  | 129/170 [01:01<00:17,  2.33it/s, loss=0.0168]\nval @ step 300:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 300:   4%|▍         | 1/23 [00:00<00:03,  6.14it/s]\u001b[A\nval @ step 300:   9%|▊         | 2/23 [00:00<00:03,  6.10it/s]\u001b[A\nval @ step 300:  13%|█▎        | 3/23 [00:00<00:03,  6.11it/s]\u001b[A\nval @ step 300:  17%|█▋        | 4/23 [00:00<00:03,  6.14it/s]\u001b[A\nval @ step 300:  22%|██▏       | 5/23 [00:00<00:02,  6.11it/s]\u001b[A\nval @ step 300:  26%|██▌       | 6/23 [00:00<00:02,  6.13it/s]\u001b[A\nval @ step 300:  30%|███       | 7/23 [00:01<00:02,  6.09it/s]\u001b[A\nval @ step 300:  35%|███▍      | 8/23 [00:01<00:02,  6.06it/s]\u001b[A\nval @ step 300:  39%|███▉      | 9/23 [00:01<00:02,  6.07it/s]\u001b[A\nval @ step 300:  43%|████▎     | 10/23 [00:01<00:02,  6.11it/s]\u001b[A\nval @ step 300:  48%|████▊     | 11/23 [00:01<00:01,  6.16it/s]\u001b[A\nval @ step 300:  52%|█████▏    | 12/23 [00:01<00:01,  6.14it/s]\u001b[A\nval @ step 300:  57%|█████▋    | 13/23 [00:02<00:01,  6.14it/s]\u001b[A\nval @ step 300:  61%|██████    | 14/23 [00:02<00:01,  6.16it/s]\u001b[A\nval @ step 300:  65%|██████▌   | 15/23 [00:02<00:01,  6.15it/s]\u001b[A\nval @ step 300:  70%|██████▉   | 16/23 [00:02<00:01,  6.11it/s]\u001b[A\nval @ step 300:  74%|███████▍  | 17/23 [00:02<00:00,  6.12it/s]\u001b[A\nval @ step 300:  78%|███████▊  | 18/23 [00:02<00:00,  6.05it/s]\u001b[A\nval @ step 300:  83%|████████▎ | 19/23 [00:03<00:00,  6.02it/s]\u001b[A\nval @ step 300:  87%|████████▋ | 20/23 [00:03<00:00,  5.97it/s]\u001b[A\nval @ step 300:  91%|█████████▏| 21/23 [00:03<00:00,  6.02it/s]\u001b[A\nval @ step 300: 100%|██████████| 23/23 [00:03<00:00,  6.23it/s]\u001b[A\nEpoch 2 [train]:  76%|███████▋  | 130/170 [01:05<01:01,  1.54s/it, loss=0.0168]","output_type":"stream"},{"name":"stdout","text":"\nStep 300: val_loss = 0.0280, val_UAR = 0.6459\n  No UAR improvement for 1 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [train]: 100%|██████████| 170/170 [01:22<00:00,  2.06it/s, loss=0.0167]\nEpoch 3 [train]:  35%|███▍      | 59/170 [00:28<00:52,  2.11it/s, loss=0.012] \nval @ step 400:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 400:   4%|▍         | 1/23 [00:00<00:03,  6.22it/s]\u001b[A\nval @ step 400:   9%|▊         | 2/23 [00:00<00:03,  5.96it/s]\u001b[A\nval @ step 400:  13%|█▎        | 3/23 [00:00<00:03,  6.04it/s]\u001b[A\nval @ step 400:  17%|█▋        | 4/23 [00:00<00:03,  6.06it/s]\u001b[A\nval @ step 400:  22%|██▏       | 5/23 [00:00<00:02,  6.01it/s]\u001b[A\nval @ step 400:  26%|██▌       | 6/23 [00:00<00:02,  6.04it/s]\u001b[A\nval @ step 400:  30%|███       | 7/23 [00:01<00:02,  6.05it/s]\u001b[A\nval @ step 400:  35%|███▍      | 8/23 [00:01<00:02,  6.10it/s]\u001b[A\nval @ step 400:  39%|███▉      | 9/23 [00:01<00:02,  6.08it/s]\u001b[A\nval @ step 400:  43%|████▎     | 10/23 [00:01<00:02,  6.05it/s]\u001b[A\nval @ step 400:  48%|████▊     | 11/23 [00:01<00:01,  6.02it/s]\u001b[A\nval @ step 400:  52%|█████▏    | 12/23 [00:01<00:01,  6.07it/s]\u001b[A\nval @ step 400:  57%|█████▋    | 13/23 [00:02<00:01,  6.07it/s]\u001b[A\nval @ step 400:  61%|██████    | 14/23 [00:02<00:01,  6.06it/s]\u001b[A\nval @ step 400:  65%|██████▌   | 15/23 [00:02<00:01,  6.06it/s]\u001b[A\nval @ step 400:  70%|██████▉   | 16/23 [00:02<00:01,  6.03it/s]\u001b[A\nval @ step 400:  74%|███████▍  | 17/23 [00:02<00:01,  5.96it/s]\u001b[A\nval @ step 400:  78%|███████▊  | 18/23 [00:02<00:00,  5.98it/s]\u001b[A\nval @ step 400:  83%|████████▎ | 19/23 [00:03<00:00,  6.02it/s]\u001b[A\nval @ step 400:  87%|████████▋ | 20/23 [00:03<00:00,  6.02it/s]\u001b[A\nval @ step 400:  91%|█████████▏| 21/23 [00:03<00:00,  6.06it/s]\u001b[A\nval @ step 400: 100%|██████████| 23/23 [00:03<00:00,  6.20it/s]\u001b[A\nEpoch 3 [train]:  35%|███▌      | 60/170 [00:32<02:54,  1.59s/it, loss=0.012]","output_type":"stream"},{"name":"stdout","text":"\nStep 400: val_loss = 0.0315, val_UAR = 0.6446\n  No UAR improvement for 2 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [train]:  94%|█████████▎| 159/170 [01:15<00:04,  2.28it/s, loss=0.00968]\nval @ step 500:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 500:   4%|▍         | 1/23 [00:00<00:03,  5.96it/s]\u001b[A\nval @ step 500:   9%|▊         | 2/23 [00:00<00:03,  5.98it/s]\u001b[A\nval @ step 500:  13%|█▎        | 3/23 [00:00<00:03,  6.05it/s]\u001b[A\nval @ step 500:  17%|█▋        | 4/23 [00:00<00:03,  6.05it/s]\u001b[A\nval @ step 500:  22%|██▏       | 5/23 [00:00<00:03,  5.97it/s]\u001b[A\nval @ step 500:  26%|██▌       | 6/23 [00:01<00:02,  5.97it/s]\u001b[A\nval @ step 500:  30%|███       | 7/23 [00:01<00:02,  5.98it/s]\u001b[A\nval @ step 500:  35%|███▍      | 8/23 [00:01<00:02,  6.01it/s]\u001b[A\nval @ step 500:  39%|███▉      | 9/23 [00:01<00:02,  6.03it/s]\u001b[A\nval @ step 500:  43%|████▎     | 10/23 [00:01<00:02,  6.00it/s]\u001b[A\nval @ step 500:  48%|████▊     | 11/23 [00:01<00:01,  6.03it/s]\u001b[A\nval @ step 500:  52%|█████▏    | 12/23 [00:02<00:01,  5.81it/s]\u001b[A\nval @ step 500:  57%|█████▋    | 13/23 [00:02<00:01,  5.93it/s]\u001b[A\nval @ step 500:  61%|██████    | 14/23 [00:02<00:01,  6.03it/s]\u001b[A\nval @ step 500:  65%|██████▌   | 15/23 [00:02<00:01,  5.95it/s]\u001b[A\nval @ step 500:  70%|██████▉   | 16/23 [00:02<00:01,  5.87it/s]\u001b[A\nval @ step 500:  74%|███████▍  | 17/23 [00:02<00:01,  5.91it/s]\u001b[A\nval @ step 500:  78%|███████▊  | 18/23 [00:03<00:00,  5.95it/s]\u001b[A\nval @ step 500:  83%|████████▎ | 19/23 [00:03<00:00,  5.93it/s]\u001b[A\nval @ step 500:  87%|████████▋ | 20/23 [00:03<00:00,  5.97it/s]\u001b[A\nval @ step 500:  91%|█████████▏| 21/23 [00:03<00:00,  5.97it/s]\u001b[A\nval @ step 500: 100%|██████████| 23/23 [00:03<00:00,  6.12it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"\nStep 500: val_loss = 0.0270, val_UAR = 0.6662\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [train]:  94%|█████████▍| 160/170 [01:20<00:18,  1.90s/it, loss=0.00968]","output_type":"stream"},{"name":"stdout","text":"  -> New best model (step 500) saved to /kaggle/working/language_fluencybank.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [train]: 100%|██████████| 170/170 [01:24<00:00,  2.01it/s, loss=0.00968]\nEpoch 4 [train]:  52%|█████▏    | 89/170 [00:43<00:39,  2.07it/s, loss=0.00814]\nval @ step 600:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 600:   4%|▍         | 1/23 [00:00<00:03,  6.20it/s]\u001b[A\nval @ step 600:   9%|▊         | 2/23 [00:00<00:03,  5.96it/s]\u001b[A\nval @ step 600:  13%|█▎        | 3/23 [00:00<00:03,  6.08it/s]\u001b[A\nval @ step 600:  17%|█▋        | 4/23 [00:00<00:03,  6.04it/s]\u001b[A\nval @ step 600:  22%|██▏       | 5/23 [00:00<00:02,  6.07it/s]\u001b[A\nval @ step 600:  26%|██▌       | 6/23 [00:00<00:02,  6.05it/s]\u001b[A\nval @ step 600:  30%|███       | 7/23 [00:01<00:02,  6.07it/s]\u001b[A\nval @ step 600:  35%|███▍      | 8/23 [00:01<00:02,  5.88it/s]\u001b[A\nval @ step 600:  39%|███▉      | 9/23 [00:01<00:02,  5.84it/s]\u001b[A\nval @ step 600:  43%|████▎     | 10/23 [00:01<00:02,  5.85it/s]\u001b[A\nval @ step 600:  48%|████▊     | 11/23 [00:01<00:02,  5.92it/s]\u001b[A\nval @ step 600:  52%|█████▏    | 12/23 [00:02<00:01,  6.00it/s]\u001b[A\nval @ step 600:  57%|█████▋    | 13/23 [00:02<00:01,  6.04it/s]\u001b[A\nval @ step 600:  61%|██████    | 14/23 [00:02<00:01,  6.06it/s]\u001b[A\nval @ step 600:  65%|██████▌   | 15/23 [00:02<00:01,  6.08it/s]\u001b[A\nval @ step 600:  70%|██████▉   | 16/23 [00:02<00:01,  6.08it/s]\u001b[A\nval @ step 600:  74%|███████▍  | 17/23 [00:02<00:00,  6.05it/s]\u001b[A\nval @ step 600:  78%|███████▊  | 18/23 [00:02<00:00,  6.05it/s]\u001b[A\nval @ step 600:  83%|████████▎ | 19/23 [00:03<00:00,  6.03it/s]\u001b[A\nval @ step 600:  87%|████████▋ | 20/23 [00:03<00:00,  5.91it/s]\u001b[A\nval @ step 600:  91%|█████████▏| 21/23 [00:03<00:00,  5.93it/s]\u001b[A\nval @ step 600: 100%|██████████| 23/23 [00:03<00:00,  6.13it/s]\u001b[A\nEpoch 4 [train]:  53%|█████▎    | 90/170 [00:47<02:08,  1.61s/it, loss=0.00814]","output_type":"stream"},{"name":"stdout","text":"\nStep 600: val_loss = 0.0291, val_UAR = 0.6618\n  No UAR improvement for 1 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 [train]: 100%|██████████| 170/170 [01:21<00:00,  2.08it/s, loss=0.00717]\nEpoch 5 [train]:  11%|█         | 19/170 [00:09<01:12,  2.09it/s, loss=0.00894]\nval @ step 700:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 700:   4%|▍         | 1/23 [00:00<00:03,  6.36it/s]\u001b[A\nval @ step 700:   9%|▊         | 2/23 [00:00<00:03,  6.08it/s]\u001b[A\nval @ step 700:  13%|█▎        | 3/23 [00:00<00:03,  6.08it/s]\u001b[A\nval @ step 700:  17%|█▋        | 4/23 [00:00<00:03,  6.17it/s]\u001b[A\nval @ step 700:  22%|██▏       | 5/23 [00:00<00:02,  6.23it/s]\u001b[A\nval @ step 700:  26%|██▌       | 6/23 [00:00<00:02,  6.28it/s]\u001b[A\nval @ step 700:  30%|███       | 7/23 [00:01<00:02,  6.31it/s]\u001b[A\nval @ step 700:  35%|███▍      | 8/23 [00:01<00:02,  6.31it/s]\u001b[A\nval @ step 700:  39%|███▉      | 9/23 [00:01<00:02,  6.31it/s]\u001b[A\nval @ step 700:  43%|████▎     | 10/23 [00:01<00:02,  6.30it/s]\u001b[A\nval @ step 700:  48%|████▊     | 11/23 [00:01<00:01,  6.32it/s]\u001b[A\nval @ step 700:  52%|█████▏    | 12/23 [00:01<00:01,  6.26it/s]\u001b[A\nval @ step 700:  57%|█████▋    | 13/23 [00:02<00:01,  6.25it/s]\u001b[A\nval @ step 700:  61%|██████    | 14/23 [00:02<00:01,  6.19it/s]\u001b[A\nval @ step 700:  65%|██████▌   | 15/23 [00:02<00:01,  6.19it/s]\u001b[A\nval @ step 700:  70%|██████▉   | 16/23 [00:02<00:01,  6.19it/s]\u001b[A\nval @ step 700:  74%|███████▍  | 17/23 [00:02<00:00,  6.24it/s]\u001b[A\nval @ step 700:  78%|███████▊  | 18/23 [00:02<00:00,  6.24it/s]\u001b[A\nval @ step 700:  83%|████████▎ | 19/23 [00:03<00:00,  6.24it/s]\u001b[A\nval @ step 700:  87%|████████▋ | 20/23 [00:03<00:00,  6.26it/s]\u001b[A\nval @ step 700:  91%|█████████▏| 21/23 [00:03<00:00,  6.30it/s]\u001b[A\nval @ step 700: 100%|██████████| 23/23 [00:03<00:00,  6.41it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"\nStep 700: val_loss = 0.0269, val_UAR = 0.6669\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [train]:  12%|█▏        | 20/170 [00:14<04:41,  1.88s/it, loss=0.00894]","output_type":"stream"},{"name":"stdout","text":"  -> New best model (step 700) saved to /kaggle/working/language_fluencybank.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [train]:  70%|███████   | 119/170 [00:57<00:22,  2.31it/s, loss=0.00558]\nval @ step 800:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 800:   4%|▍         | 1/23 [00:00<00:03,  6.50it/s]\u001b[A\nval @ step 800:   9%|▊         | 2/23 [00:00<00:03,  6.39it/s]\u001b[A\nval @ step 800:  13%|█▎        | 3/23 [00:00<00:03,  6.35it/s]\u001b[A\nval @ step 800:  17%|█▋        | 4/23 [00:00<00:02,  6.37it/s]\u001b[A\nval @ step 800:  22%|██▏       | 5/23 [00:00<00:02,  6.41it/s]\u001b[A\nval @ step 800:  26%|██▌       | 6/23 [00:00<00:02,  6.39it/s]\u001b[A\nval @ step 800:  30%|███       | 7/23 [00:01<00:02,  6.40it/s]\u001b[A\nval @ step 800:  35%|███▍      | 8/23 [00:01<00:02,  6.34it/s]\u001b[A\nval @ step 800:  39%|███▉      | 9/23 [00:01<00:02,  6.37it/s]\u001b[A\nval @ step 800:  43%|████▎     | 10/23 [00:01<00:02,  6.36it/s]\u001b[A\nval @ step 800:  48%|████▊     | 11/23 [00:01<00:01,  6.32it/s]\u001b[A\nval @ step 800:  52%|█████▏    | 12/23 [00:01<00:01,  6.31it/s]\u001b[A\nval @ step 800:  57%|█████▋    | 13/23 [00:02<00:01,  6.29it/s]\u001b[A\nval @ step 800:  61%|██████    | 14/23 [00:02<00:01,  6.27it/s]\u001b[A\nval @ step 800:  65%|██████▌   | 15/23 [00:02<00:01,  6.27it/s]\u001b[A\nval @ step 800:  70%|██████▉   | 16/23 [00:02<00:01,  6.27it/s]\u001b[A\nval @ step 800:  74%|███████▍  | 17/23 [00:02<00:00,  6.27it/s]\u001b[A\nval @ step 800:  78%|███████▊  | 18/23 [00:02<00:00,  6.21it/s]\u001b[A\nval @ step 800:  83%|████████▎ | 19/23 [00:03<00:00,  6.23it/s]\u001b[A\nval @ step 800:  87%|████████▋ | 20/23 [00:03<00:00,  6.22it/s]\u001b[A\nval @ step 800:  91%|█████████▏| 21/23 [00:03<00:00,  6.21it/s]\u001b[A\nval @ step 800: 100%|██████████| 23/23 [00:03<00:00,  6.46it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"\nStep 800: val_loss = 0.0281, val_UAR = 0.6682\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [train]:  71%|███████   | 120/170 [01:02<01:31,  1.84s/it, loss=0.00558]","output_type":"stream"},{"name":"stdout","text":"  -> New best model (step 800) saved to /kaggle/working/language_fluencybank.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [train]: 100%|██████████| 170/170 [01:23<00:00,  2.03it/s, loss=0.00507]\nEpoch 6 [train]:  29%|██▉       | 49/170 [00:23<00:57,  2.10it/s, loss=0.00469]\nval @ step 900:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 900:   4%|▍         | 1/23 [00:00<00:03,  6.03it/s]\u001b[A\nval @ step 900:   9%|▊         | 2/23 [00:00<00:03,  6.15it/s]\u001b[A\nval @ step 900:  13%|█▎        | 3/23 [00:00<00:03,  6.22it/s]\u001b[A\nval @ step 900:  17%|█▋        | 4/23 [00:00<00:03,  6.31it/s]\u001b[A\nval @ step 900:  22%|██▏       | 5/23 [00:00<00:02,  6.33it/s]\u001b[A\nval @ step 900:  26%|██▌       | 6/23 [00:00<00:02,  6.36it/s]\u001b[A\nval @ step 900:  30%|███       | 7/23 [00:01<00:02,  6.34it/s]\u001b[A\nval @ step 900:  35%|███▍      | 8/23 [00:01<00:02,  6.34it/s]\u001b[A\nval @ step 900:  39%|███▉      | 9/23 [00:01<00:02,  6.35it/s]\u001b[A\nval @ step 900:  43%|████▎     | 10/23 [00:01<00:02,  6.26it/s]\u001b[A\nval @ step 900:  48%|████▊     | 11/23 [00:01<00:01,  6.23it/s]\u001b[A\nval @ step 900:  52%|█████▏    | 12/23 [00:01<00:01,  6.24it/s]\u001b[A\nval @ step 900:  57%|█████▋    | 13/23 [00:02<00:01,  6.29it/s]\u001b[A\nval @ step 900:  61%|██████    | 14/23 [00:02<00:01,  6.34it/s]\u001b[A\nval @ step 900:  65%|██████▌   | 15/23 [00:02<00:01,  6.32it/s]\u001b[A\nval @ step 900:  70%|██████▉   | 16/23 [00:02<00:01,  6.37it/s]\u001b[A\nval @ step 900:  74%|███████▍  | 17/23 [00:02<00:00,  6.28it/s]\u001b[A\nval @ step 900:  78%|███████▊  | 18/23 [00:02<00:00,  6.21it/s]\u001b[A\nval @ step 900:  83%|████████▎ | 19/23 [00:03<00:00,  6.18it/s]\u001b[A\nval @ step 900:  87%|████████▋ | 20/23 [00:03<00:00,  6.20it/s]\u001b[A\nval @ step 900:  91%|█████████▏| 21/23 [00:03<00:00,  6.22it/s]\u001b[A\nval @ step 900: 100%|██████████| 23/23 [00:03<00:00,  6.43it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"\nStep 900: val_loss = 0.0314, val_UAR = 0.6714\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 [train]:  29%|██▉       | 50/170 [00:28<03:47,  1.90s/it, loss=0.00469]","output_type":"stream"},{"name":"stdout","text":"  -> New best model (step 900) saved to /kaggle/working/language_fluencybank.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 [train]:  88%|████████▊ | 149/170 [01:11<00:09,  2.30it/s, loss=0.00444]\nval @ step 1000:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 1000:   4%|▍         | 1/23 [00:00<00:03,  6.40it/s]\u001b[A\nval @ step 1000:   9%|▊         | 2/23 [00:00<00:03,  6.06it/s]\u001b[A\nval @ step 1000:  13%|█▎        | 3/23 [00:00<00:03,  6.01it/s]\u001b[A\nval @ step 1000:  17%|█▋        | 4/23 [00:00<00:03,  6.14it/s]\u001b[A\nval @ step 1000:  22%|██▏       | 5/23 [00:00<00:02,  6.21it/s]\u001b[A\nval @ step 1000:  26%|██▌       | 6/23 [00:00<00:02,  6.15it/s]\u001b[A\nval @ step 1000:  30%|███       | 7/23 [00:01<00:02,  6.23it/s]\u001b[A\nval @ step 1000:  35%|███▍      | 8/23 [00:01<00:02,  6.26it/s]\u001b[A\nval @ step 1000:  39%|███▉      | 9/23 [00:01<00:02,  6.31it/s]\u001b[A\nval @ step 1000:  43%|████▎     | 10/23 [00:01<00:02,  6.30it/s]\u001b[A\nval @ step 1000:  48%|████▊     | 11/23 [00:01<00:01,  6.30it/s]\u001b[A\nval @ step 1000:  52%|█████▏    | 12/23 [00:01<00:01,  6.33it/s]\u001b[A\nval @ step 1000:  57%|█████▋    | 13/23 [00:02<00:01,  6.32it/s]\u001b[A\nval @ step 1000:  61%|██████    | 14/23 [00:02<00:01,  6.29it/s]\u001b[A\nval @ step 1000:  65%|██████▌   | 15/23 [00:02<00:01,  6.26it/s]\u001b[A\nval @ step 1000:  70%|██████▉   | 16/23 [00:02<00:01,  6.24it/s]\u001b[A\nval @ step 1000:  74%|███████▍  | 17/23 [00:02<00:00,  6.27it/s]\u001b[A\nval @ step 1000:  78%|███████▊  | 18/23 [00:02<00:00,  6.29it/s]\u001b[A\nval @ step 1000:  83%|████████▎ | 19/23 [00:03<00:00,  6.25it/s]\u001b[A\nval @ step 1000:  87%|████████▋ | 20/23 [00:03<00:00,  6.20it/s]\u001b[A\nval @ step 1000:  91%|█████████▏| 21/23 [00:03<00:00,  6.14it/s]\u001b[A\nval @ step 1000: 100%|██████████| 23/23 [00:03<00:00,  6.38it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"\nStep 1000: val_loss = 0.0324, val_UAR = 0.6755\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 [train]:  88%|████████▊ | 150/170 [01:16<00:36,  1.85s/it, loss=0.00444]","output_type":"stream"},{"name":"stdout","text":"  -> New best model (step 1000) saved to /kaggle/working/language_fluencybank.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 [train]: 100%|██████████| 170/170 [01:25<00:00,  2.00it/s, loss=0.00409]\nEpoch 7 [train]:  46%|████▋     | 79/170 [00:38<00:43,  2.08it/s, loss=0.00497]\nval @ step 1100:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 1100:   4%|▍         | 1/23 [00:00<00:03,  6.48it/s]\u001b[A\nval @ step 1100:   9%|▊         | 2/23 [00:00<00:03,  6.26it/s]\u001b[A\nval @ step 1100:  13%|█▎        | 3/23 [00:00<00:03,  6.22it/s]\u001b[A\nval @ step 1100:  17%|█▋        | 4/23 [00:00<00:03,  6.13it/s]\u001b[A\nval @ step 1100:  22%|██▏       | 5/23 [00:00<00:02,  6.16it/s]\u001b[A\nval @ step 1100:  26%|██▌       | 6/23 [00:00<00:02,  6.16it/s]\u001b[A\nval @ step 1100:  30%|███       | 7/23 [00:01<00:02,  6.18it/s]\u001b[A\nval @ step 1100:  35%|███▍      | 8/23 [00:01<00:02,  6.14it/s]\u001b[A\nval @ step 1100:  39%|███▉      | 9/23 [00:01<00:02,  6.19it/s]\u001b[A\nval @ step 1100:  43%|████▎     | 10/23 [00:01<00:02,  6.24it/s]\u001b[A\nval @ step 1100:  48%|████▊     | 11/23 [00:01<00:01,  6.17it/s]\u001b[A\nval @ step 1100:  52%|█████▏    | 12/23 [00:01<00:01,  6.24it/s]\u001b[A\nval @ step 1100:  57%|█████▋    | 13/23 [00:02<00:01,  6.27it/s]\u001b[A\nval @ step 1100:  61%|██████    | 14/23 [00:02<00:01,  6.27it/s]\u001b[A\nval @ step 1100:  65%|██████▌   | 15/23 [00:02<00:01,  6.21it/s]\u001b[A\nval @ step 1100:  70%|██████▉   | 16/23 [00:02<00:01,  6.27it/s]\u001b[A\nval @ step 1100:  74%|███████▍  | 17/23 [00:02<00:00,  6.28it/s]\u001b[A\nval @ step 1100:  78%|███████▊  | 18/23 [00:02<00:00,  6.24it/s]\u001b[A\nval @ step 1100:  83%|████████▎ | 19/23 [00:03<00:00,  6.23it/s]\u001b[A\nval @ step 1100:  87%|████████▋ | 20/23 [00:03<00:00,  6.03it/s]\u001b[A\nval @ step 1100:  91%|█████████▏| 21/23 [00:03<00:00,  6.06it/s]\u001b[A\nval @ step 1100: 100%|██████████| 23/23 [00:03<00:00,  6.34it/s]\u001b[A\nEpoch 7 [train]:  47%|████▋     | 80/170 [00:41<02:21,  1.57s/it, loss=0.00497]","output_type":"stream"},{"name":"stdout","text":"\nStep 1100: val_loss = 0.0336, val_UAR = 0.6627\n  No UAR improvement for 1 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 [train]: 100%|██████████| 170/170 [01:20<00:00,  2.10it/s, loss=0.00406]\nEpoch 8 [train]:   5%|▌         | 9/170 [00:04<01:16,  2.09it/s, loss=0.00362] \nval @ step 1200:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 1200:   4%|▍         | 1/23 [00:00<00:03,  6.25it/s]\u001b[A\nval @ step 1200:   9%|▊         | 2/23 [00:00<00:03,  6.20it/s]\u001b[A\nval @ step 1200:  13%|█▎        | 3/23 [00:00<00:03,  6.13it/s]\u001b[A\nval @ step 1200:  17%|█▋        | 4/23 [00:00<00:03,  6.20it/s]\u001b[A\nval @ step 1200:  22%|██▏       | 5/23 [00:00<00:02,  6.21it/s]\u001b[A\nval @ step 1200:  26%|██▌       | 6/23 [00:00<00:02,  6.24it/s]\u001b[A\nval @ step 1200:  30%|███       | 7/23 [00:01<00:02,  6.20it/s]\u001b[A\nval @ step 1200:  35%|███▍      | 8/23 [00:01<00:02,  6.17it/s]\u001b[A\nval @ step 1200:  39%|███▉      | 9/23 [00:01<00:02,  6.21it/s]\u001b[A\nval @ step 1200:  43%|████▎     | 10/23 [00:01<00:02,  6.25it/s]\u001b[A\nval @ step 1200:  48%|████▊     | 11/23 [00:01<00:01,  6.28it/s]\u001b[A\nval @ step 1200:  52%|█████▏    | 12/23 [00:01<00:01,  6.31it/s]\u001b[A\nval @ step 1200:  57%|█████▋    | 13/23 [00:02<00:01,  6.29it/s]\u001b[A\nval @ step 1200:  61%|██████    | 14/23 [00:02<00:01,  6.33it/s]\u001b[A\nval @ step 1200:  65%|██████▌   | 15/23 [00:02<00:01,  6.32it/s]\u001b[A\nval @ step 1200:  70%|██████▉   | 16/23 [00:02<00:01,  6.28it/s]\u001b[A\nval @ step 1200:  74%|███████▍  | 17/23 [00:02<00:00,  6.28it/s]\u001b[A\nval @ step 1200:  78%|███████▊  | 18/23 [00:02<00:00,  6.27it/s]\u001b[A\nval @ step 1200:  83%|████████▎ | 19/23 [00:03<00:00,  6.27it/s]\u001b[A\nval @ step 1200:  87%|████████▋ | 20/23 [00:03<00:00,  6.22it/s]\u001b[A\nval @ step 1200:  91%|█████████▏| 21/23 [00:03<00:00,  6.18it/s]\u001b[A\nval @ step 1200: 100%|██████████| 23/23 [00:03<00:00,  6.40it/s]\u001b[A\nEpoch 8 [train]:   6%|▌         | 10/170 [00:08<04:14,  1.59s/it, loss=0.00362]","output_type":"stream"},{"name":"stdout","text":"\nStep 1200: val_loss = 0.0349, val_UAR = 0.6410\n  No UAR improvement for 2 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 [train]:  64%|██████▍   | 109/170 [00:52<00:26,  2.27it/s, loss=0.00333]\nval @ step 1300:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 1300:   4%|▍         | 1/23 [00:00<00:03,  6.23it/s]\u001b[A\nval @ step 1300:   9%|▊         | 2/23 [00:00<00:03,  6.11it/s]\u001b[A\nval @ step 1300:  13%|█▎        | 3/23 [00:00<00:03,  6.17it/s]\u001b[A\nval @ step 1300:  17%|█▋        | 4/23 [00:00<00:03,  6.12it/s]\u001b[A\nval @ step 1300:  22%|██▏       | 5/23 [00:00<00:02,  6.15it/s]\u001b[A\nval @ step 1300:  26%|██▌       | 6/23 [00:00<00:02,  6.23it/s]\u001b[A\nval @ step 1300:  30%|███       | 7/23 [00:01<00:02,  6.25it/s]\u001b[A\nval @ step 1300:  35%|███▍      | 8/23 [00:01<00:02,  6.24it/s]\u001b[A\nval @ step 1300:  39%|███▉      | 9/23 [00:01<00:02,  6.26it/s]\u001b[A\nval @ step 1300:  43%|████▎     | 10/23 [00:01<00:02,  6.30it/s]\u001b[A\nval @ step 1300:  48%|████▊     | 11/23 [00:01<00:01,  6.27it/s]\u001b[A\nval @ step 1300:  52%|█████▏    | 12/23 [00:01<00:01,  6.24it/s]\u001b[A\nval @ step 1300:  57%|█████▋    | 13/23 [00:02<00:01,  6.23it/s]\u001b[A\nval @ step 1300:  61%|██████    | 14/23 [00:02<00:01,  6.27it/s]\u001b[A\nval @ step 1300:  65%|██████▌   | 15/23 [00:02<00:01,  6.26it/s]\u001b[A\nval @ step 1300:  70%|██████▉   | 16/23 [00:02<00:01,  6.27it/s]\u001b[A\nval @ step 1300:  74%|███████▍  | 17/23 [00:02<00:00,  6.26it/s]\u001b[A\nval @ step 1300:  78%|███████▊  | 18/23 [00:02<00:00,  6.27it/s]\u001b[A\nval @ step 1300:  83%|████████▎ | 19/23 [00:03<00:00,  6.23it/s]\u001b[A\nval @ step 1300:  87%|████████▋ | 20/23 [00:03<00:00,  6.23it/s]\u001b[A\nval @ step 1300:  91%|█████████▏| 21/23 [00:03<00:00,  6.24it/s]\u001b[A\nval @ step 1300: 100%|██████████| 23/23 [00:03<00:00,  6.40it/s]\u001b[A\nEpoch 8 [train]:  65%|██████▍   | 110/170 [00:55<01:31,  1.52s/it, loss=0.00333]","output_type":"stream"},{"name":"stdout","text":"\nStep 1300: val_loss = 0.0354, val_UAR = 0.6620\n  No UAR improvement for 3 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 [train]: 100%|██████████| 170/170 [01:21<00:00,  2.08it/s, loss=0.00304]\nEpoch 9 [train]:  23%|██▎       | 39/170 [00:19<01:04,  2.03it/s, loss=0.00412]\nval @ step 1400:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 1400:   4%|▍         | 1/23 [00:00<00:03,  5.98it/s]\u001b[A\nval @ step 1400:   9%|▊         | 2/23 [00:00<00:03,  6.04it/s]\u001b[A\nval @ step 1400:  13%|█▎        | 3/23 [00:00<00:03,  6.13it/s]\u001b[A\nval @ step 1400:  17%|█▋        | 4/23 [00:00<00:03,  6.20it/s]\u001b[A\nval @ step 1400:  22%|██▏       | 5/23 [00:00<00:02,  6.20it/s]\u001b[A\nval @ step 1400:  26%|██▌       | 6/23 [00:00<00:02,  6.12it/s]\u001b[A\nval @ step 1400:  30%|███       | 7/23 [00:01<00:02,  5.95it/s]\u001b[A\nval @ step 1400:  35%|███▍      | 8/23 [00:01<00:02,  6.05it/s]\u001b[A\nval @ step 1400:  39%|███▉      | 9/23 [00:01<00:02,  6.08it/s]\u001b[A\nval @ step 1400:  43%|████▎     | 10/23 [00:01<00:02,  6.09it/s]\u001b[A\nval @ step 1400:  48%|████▊     | 11/23 [00:01<00:01,  6.10it/s]\u001b[A\nval @ step 1400:  52%|█████▏    | 12/23 [00:01<00:01,  6.10it/s]\u001b[A\nval @ step 1400:  57%|█████▋    | 13/23 [00:02<00:01,  6.13it/s]\u001b[A\nval @ step 1400:  61%|██████    | 14/23 [00:02<00:01,  6.13it/s]\u001b[A\nval @ step 1400:  65%|██████▌   | 15/23 [00:02<00:01,  6.08it/s]\u001b[A\nval @ step 1400:  70%|██████▉   | 16/23 [00:02<00:01,  6.13it/s]\u001b[A\nval @ step 1400:  74%|███████▍  | 17/23 [00:02<00:00,  6.16it/s]\u001b[A\nval @ step 1400:  78%|███████▊  | 18/23 [00:02<00:00,  6.11it/s]\u001b[A\nval @ step 1400:  83%|████████▎ | 19/23 [00:03<00:00,  6.10it/s]\u001b[A\nval @ step 1400:  87%|████████▋ | 20/23 [00:03<00:00,  6.16it/s]\u001b[A\nval @ step 1400:  91%|█████████▏| 21/23 [00:03<00:00,  6.15it/s]\u001b[A\nval @ step 1400: 100%|██████████| 23/23 [00:03<00:00,  6.28it/s]\u001b[A\nEpoch 9 [train]:  24%|██▎       | 40/170 [00:22<03:26,  1.59s/it, loss=0.00412]","output_type":"stream"},{"name":"stdout","text":"\nStep 1400: val_loss = 0.0332, val_UAR = 0.6549\n  No UAR improvement for 4 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 [train]:  82%|████████▏ | 139/170 [01:06<00:13,  2.29it/s, loss=0.00287]\nval @ step 1500:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 1500:   4%|▍         | 1/23 [00:00<00:04,  5.21it/s]\u001b[A\nval @ step 1500:   9%|▊         | 2/23 [00:00<00:03,  5.79it/s]\u001b[A\nval @ step 1500:  13%|█▎        | 3/23 [00:00<00:03,  5.91it/s]\u001b[A\nval @ step 1500:  17%|█▋        | 4/23 [00:00<00:03,  6.12it/s]\u001b[A\nval @ step 1500:  22%|██▏       | 5/23 [00:00<00:02,  6.20it/s]\u001b[A\nval @ step 1500:  26%|██▌       | 6/23 [00:00<00:02,  6.19it/s]\u001b[A\nval @ step 1500:  30%|███       | 7/23 [00:01<00:02,  6.20it/s]\u001b[A\nval @ step 1500:  35%|███▍      | 8/23 [00:01<00:02,  6.26it/s]\u001b[A\nval @ step 1500:  39%|███▉      | 9/23 [00:01<00:02,  6.19it/s]\u001b[A\nval @ step 1500:  43%|████▎     | 10/23 [00:01<00:02,  5.88it/s]\u001b[A\nval @ step 1500:  48%|████▊     | 11/23 [00:01<00:02,  5.80it/s]\u001b[A\nval @ step 1500:  52%|█████▏    | 12/23 [00:01<00:01,  5.97it/s]\u001b[A\nval @ step 1500:  57%|█████▋    | 13/23 [00:02<00:01,  6.02it/s]\u001b[A\nval @ step 1500:  61%|██████    | 14/23 [00:02<00:01,  6.12it/s]\u001b[A\nval @ step 1500:  65%|██████▌   | 15/23 [00:02<00:01,  6.17it/s]\u001b[A\nval @ step 1500:  70%|██████▉   | 16/23 [00:02<00:01,  6.18it/s]\u001b[A\nval @ step 1500:  74%|███████▍  | 17/23 [00:02<00:00,  6.09it/s]\u001b[A\nval @ step 1500:  78%|███████▊  | 18/23 [00:02<00:00,  6.13it/s]\u001b[A\nval @ step 1500:  83%|████████▎ | 19/23 [00:03<00:00,  6.15it/s]\u001b[A\nval @ step 1500:  87%|████████▋ | 20/23 [00:03<00:00,  6.17it/s]\u001b[A\nval @ step 1500:  91%|█████████▏| 21/23 [00:03<00:00,  6.15it/s]\u001b[A\nval @ step 1500: 100%|██████████| 23/23 [00:03<00:00,  6.24it/s]\u001b[A\nEpoch 9 [train]:  82%|████████▏ | 140/170 [01:10<00:46,  1.55s/it, loss=0.00287]","output_type":"stream"},{"name":"stdout","text":"\nStep 1500: val_loss = 0.0350, val_UAR = 0.6539\n  No UAR improvement for 5 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 [train]: 100%|██████████| 170/170 [01:23<00:00,  2.03it/s, loss=0.00282]\nEpoch 10 [train]:  41%|████      | 69/170 [00:34<00:50,  1.99it/s, loss=0.00265]\nval @ step 1600:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 1600:   4%|▍         | 1/23 [00:00<00:05,  4.06it/s]\u001b[A\nval @ step 1600:   9%|▊         | 2/23 [00:00<00:04,  5.07it/s]\u001b[A\nval @ step 1600:  13%|█▎        | 3/23 [00:00<00:03,  5.53it/s]\u001b[A\nval @ step 1600:  17%|█▋        | 4/23 [00:00<00:03,  5.76it/s]\u001b[A\nval @ step 1600:  22%|██▏       | 5/23 [00:00<00:03,  5.96it/s]\u001b[A\nval @ step 1600:  26%|██▌       | 6/23 [00:01<00:02,  6.04it/s]\u001b[A\nval @ step 1600:  30%|███       | 7/23 [00:01<00:02,  5.84it/s]\u001b[A\nval @ step 1600:  35%|███▍      | 8/23 [00:01<00:02,  5.85it/s]\u001b[A\nval @ step 1600:  39%|███▉      | 9/23 [00:01<00:02,  5.03it/s]\u001b[A\nval @ step 1600:  43%|████▎     | 10/23 [00:01<00:02,  5.33it/s]\u001b[A\nval @ step 1600:  48%|████▊     | 11/23 [00:01<00:02,  5.60it/s]\u001b[A\nval @ step 1600:  52%|█████▏    | 12/23 [00:02<00:01,  5.76it/s]\u001b[A\nval @ step 1600:  57%|█████▋    | 13/23 [00:02<00:01,  5.94it/s]\u001b[A\nval @ step 1600:  61%|██████    | 14/23 [00:02<00:01,  6.06it/s]\u001b[A\nval @ step 1600:  65%|██████▌   | 15/23 [00:02<00:01,  6.01it/s]\u001b[A\nval @ step 1600:  70%|██████▉   | 16/23 [00:02<00:01,  5.83it/s]\u001b[A\nval @ step 1600:  74%|███████▍  | 17/23 [00:02<00:01,  5.94it/s]\u001b[A\nval @ step 1600:  78%|███████▊  | 18/23 [00:03<00:00,  6.02it/s]\u001b[A\nval @ step 1600:  83%|████████▎ | 19/23 [00:03<00:00,  6.07it/s]\u001b[A\nval @ step 1600:  87%|████████▋ | 20/23 [00:03<00:00,  6.13it/s]\u001b[A\nval @ step 1600:  91%|█████████▏| 21/23 [00:03<00:00,  6.16it/s]\u001b[A\nval @ step 1600: 100%|██████████| 23/23 [00:03<00:00,  5.83it/s]\u001b[A\nEpoch 10 [train]:  41%|████      | 70/170 [00:37<02:48,  1.68s/it, loss=0.00265]","output_type":"stream"},{"name":"stdout","text":"\nStep 1600: val_loss = 0.0393, val_UAR = 0.6618\n  No UAR improvement for 6 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 [train]:  99%|█████████▉| 169/170 [01:22<00:00,  2.28it/s, loss=0.00221]\nval @ step 1700:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 1700:   4%|▍         | 1/23 [00:00<00:03,  6.32it/s]\u001b[A\nval @ step 1700:   9%|▊         | 2/23 [00:00<00:03,  6.06it/s]\u001b[A\nval @ step 1700:  13%|█▎        | 3/23 [00:00<00:03,  6.17it/s]\u001b[A\nval @ step 1700:  17%|█▋        | 4/23 [00:00<00:03,  6.21it/s]\u001b[A\nval @ step 1700:  22%|██▏       | 5/23 [00:00<00:02,  6.19it/s]\u001b[A\nval @ step 1700:  26%|██▌       | 6/23 [00:00<00:02,  6.23it/s]\u001b[A\nval @ step 1700:  30%|███       | 7/23 [00:01<00:02,  6.24it/s]\u001b[A\nval @ step 1700:  35%|███▍      | 8/23 [00:01<00:02,  6.26it/s]\u001b[A\nval @ step 1700:  39%|███▉      | 9/23 [00:01<00:02,  6.26it/s]\u001b[A\nval @ step 1700:  43%|████▎     | 10/23 [00:01<00:02,  5.91it/s]\u001b[A\nval @ step 1700:  48%|████▊     | 11/23 [00:01<00:01,  6.05it/s]\u001b[A\nval @ step 1700:  52%|█████▏    | 12/23 [00:01<00:01,  6.10it/s]\u001b[A\nval @ step 1700:  57%|█████▋    | 13/23 [00:02<00:01,  6.12it/s]\u001b[A\nval @ step 1700:  61%|██████    | 14/23 [00:02<00:01,  6.17it/s]\u001b[A\nval @ step 1700:  65%|██████▌   | 15/23 [00:02<00:01,  6.18it/s]\u001b[A\nval @ step 1700:  70%|██████▉   | 16/23 [00:02<00:01,  6.23it/s]\u001b[A\nval @ step 1700:  74%|███████▍  | 17/23 [00:02<00:00,  6.26it/s]\u001b[A\nval @ step 1700:  78%|███████▊  | 18/23 [00:02<00:00,  6.09it/s]\u001b[A\nval @ step 1700:  83%|████████▎ | 19/23 [00:03<00:00,  5.95it/s]\u001b[A\nval @ step 1700:  87%|████████▋ | 20/23 [00:03<00:00,  6.05it/s]\u001b[A\nval @ step 1700:  91%|█████████▏| 21/23 [00:03<00:00,  6.12it/s]\u001b[A\nval @ step 1700: 100%|██████████| 23/23 [00:03<00:00,  6.31it/s]\u001b[A\nEpoch 10 [train]: 100%|██████████| 170/170 [01:25<00:00,  1.98it/s, loss=0.00221]\n","output_type":"stream"},{"name":"stdout","text":"\nStep 1700: val_loss = 0.0421, val_UAR = 0.6551\n  No UAR improvement for 7 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 [train]:  58%|█████▊    | 99/170 [00:48<00:33,  2.09it/s, loss=0.00563]\nval @ step 1800:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 1800:   4%|▍         | 1/23 [00:00<00:03,  6.38it/s]\u001b[A\nval @ step 1800:   9%|▊         | 2/23 [00:00<00:03,  6.21it/s]\u001b[A\nval @ step 1800:  13%|█▎        | 3/23 [00:00<00:03,  6.16it/s]\u001b[A\nval @ step 1800:  17%|█▋        | 4/23 [00:00<00:03,  6.19it/s]\u001b[A\nval @ step 1800:  22%|██▏       | 5/23 [00:00<00:02,  6.05it/s]\u001b[A\nval @ step 1800:  26%|██▌       | 6/23 [00:00<00:02,  6.17it/s]\u001b[A\nval @ step 1800:  30%|███       | 7/23 [00:01<00:02,  6.23it/s]\u001b[A\nval @ step 1800:  35%|███▍      | 8/23 [00:01<00:02,  6.24it/s]\u001b[A\nval @ step 1800:  39%|███▉      | 9/23 [00:01<00:02,  6.25it/s]\u001b[A\nval @ step 1800:  43%|████▎     | 10/23 [00:01<00:02,  6.28it/s]\u001b[A\nval @ step 1800:  48%|████▊     | 11/23 [00:01<00:01,  6.26it/s]\u001b[A\nval @ step 1800:  52%|█████▏    | 12/23 [00:01<00:01,  6.27it/s]\u001b[A\nval @ step 1800:  57%|█████▋    | 13/23 [00:02<00:01,  6.29it/s]\u001b[A\nval @ step 1800:  61%|██████    | 14/23 [00:02<00:01,  6.25it/s]\u001b[A\nval @ step 1800:  65%|██████▌   | 15/23 [00:02<00:01,  6.26it/s]\u001b[A\nval @ step 1800:  70%|██████▉   | 16/23 [00:02<00:01,  6.28it/s]\u001b[A\nval @ step 1800:  74%|███████▍  | 17/23 [00:02<00:00,  6.25it/s]\u001b[A\nval @ step 1800:  78%|███████▊  | 18/23 [00:02<00:00,  6.27it/s]\u001b[A\nval @ step 1800:  83%|████████▎ | 19/23 [00:03<00:00,  6.25it/s]\u001b[A\nval @ step 1800:  87%|████████▋ | 20/23 [00:03<00:00,  6.27it/s]\u001b[A\nval @ step 1800:  91%|█████████▏| 21/23 [00:03<00:00,  6.27it/s]\u001b[A\nval @ step 1800: 100%|██████████| 23/23 [00:03<00:00,  6.40it/s]\u001b[A\nEpoch 11 [train]:  59%|█████▉    | 100/170 [00:51<01:49,  1.56s/it, loss=0.00563]","output_type":"stream"},{"name":"stdout","text":"\nStep 1800: val_loss = 0.0364, val_UAR = 0.6391\n  No UAR improvement for 8 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 [train]: 100%|██████████| 170/170 [01:21<00:00,  2.07it/s, loss=0.00441]\nEpoch 12 [train]:  17%|█▋        | 29/170 [00:14<01:07,  2.10it/s, loss=0.00361]\nval @ step 1900:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 1900:   4%|▍         | 1/23 [00:00<00:03,  6.25it/s]\u001b[A\nval @ step 1900:   9%|▊         | 2/23 [00:00<00:03,  6.28it/s]\u001b[A\nval @ step 1900:  13%|█▎        | 3/23 [00:00<00:03,  6.20it/s]\u001b[A\nval @ step 1900:  17%|█▋        | 4/23 [00:00<00:03,  6.24it/s]\u001b[A\nval @ step 1900:  22%|██▏       | 5/23 [00:00<00:02,  6.24it/s]\u001b[A\nval @ step 1900:  26%|██▌       | 6/23 [00:00<00:02,  6.29it/s]\u001b[A\nval @ step 1900:  30%|███       | 7/23 [00:01<00:02,  6.30it/s]\u001b[A\nval @ step 1900:  35%|███▍      | 8/23 [00:01<00:02,  6.27it/s]\u001b[A\nval @ step 1900:  39%|███▉      | 9/23 [00:01<00:02,  6.30it/s]\u001b[A\nval @ step 1900:  43%|████▎     | 10/23 [00:01<00:02,  6.29it/s]\u001b[A\nval @ step 1900:  48%|████▊     | 11/23 [00:01<00:01,  6.29it/s]\u001b[A\nval @ step 1900:  52%|█████▏    | 12/23 [00:01<00:01,  6.33it/s]\u001b[A\nval @ step 1900:  57%|█████▋    | 13/23 [00:02<00:01,  6.34it/s]\u001b[A\nval @ step 1900:  61%|██████    | 14/23 [00:02<00:01,  6.37it/s]\u001b[A\nval @ step 1900:  65%|██████▌   | 15/23 [00:02<00:01,  6.37it/s]\u001b[A\nval @ step 1900:  70%|██████▉   | 16/23 [00:02<00:01,  6.37it/s]\u001b[A\nval @ step 1900:  74%|███████▍  | 17/23 [00:02<00:00,  6.35it/s]\u001b[A\nval @ step 1900:  78%|███████▊  | 18/23 [00:02<00:00,  6.34it/s]\u001b[A\nval @ step 1900:  83%|████████▎ | 19/23 [00:03<00:00,  6.33it/s]\u001b[A\nval @ step 1900:  87%|████████▋ | 20/23 [00:03<00:00,  6.27it/s]\u001b[A\nval @ step 1900:  91%|█████████▏| 21/23 [00:03<00:00,  6.29it/s]\u001b[A\nval @ step 1900: 100%|██████████| 23/23 [00:03<00:00,  6.46it/s]\u001b[A\nEpoch 12 [train]:  18%|█▊        | 30/170 [00:17<03:36,  1.55s/it, loss=0.00361]","output_type":"stream"},{"name":"stdout","text":"\nStep 1900: val_loss = 0.0388, val_UAR = 0.6477\n  No UAR improvement for 9 eval(s).\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12 [train]:  76%|███████▌  | 129/170 [01:01<00:17,  2.30it/s, loss=0.00298]\nval @ step 2000:   0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\nval @ step 2000:   4%|▍         | 1/23 [00:00<00:03,  5.97it/s]\u001b[A\nval @ step 2000:   9%|▊         | 2/23 [00:00<00:03,  5.76it/s]\u001b[A\nval @ step 2000:  13%|█▎        | 3/23 [00:00<00:03,  5.98it/s]\u001b[A\nval @ step 2000:  17%|█▋        | 4/23 [00:00<00:03,  6.09it/s]\u001b[A\nval @ step 2000:  22%|██▏       | 5/23 [00:00<00:02,  6.11it/s]\u001b[A\nval @ step 2000:  26%|██▌       | 6/23 [00:00<00:02,  6.16it/s]\u001b[A\nval @ step 2000:  30%|███       | 7/23 [00:01<00:02,  6.22it/s]\u001b[A\nval @ step 2000:  35%|███▍      | 8/23 [00:01<00:02,  6.22it/s]\u001b[A\nval @ step 2000:  39%|███▉      | 9/23 [00:01<00:02,  6.23it/s]\u001b[A\nval @ step 2000:  43%|████▎     | 10/23 [00:01<00:02,  6.21it/s]\u001b[A\nval @ step 2000:  48%|████▊     | 11/23 [00:01<00:01,  6.24it/s]\u001b[A\nval @ step 2000:  52%|█████▏    | 12/23 [00:01<00:01,  6.27it/s]\u001b[A\nval @ step 2000:  57%|█████▋    | 13/23 [00:02<00:01,  6.29it/s]\u001b[A\nval @ step 2000:  61%|██████    | 14/23 [00:02<00:01,  6.30it/s]\u001b[A\nval @ step 2000:  65%|██████▌   | 15/23 [00:02<00:01,  6.32it/s]\u001b[A\nval @ step 2000:  70%|██████▉   | 16/23 [00:02<00:01,  6.33it/s]\u001b[A\nval @ step 2000:  74%|███████▍  | 17/23 [00:02<00:00,  6.29it/s]\u001b[A\nval @ step 2000:  78%|███████▊  | 18/23 [00:02<00:00,  6.15it/s]\u001b[A\nval @ step 2000:  83%|████████▎ | 19/23 [00:03<00:00,  6.18it/s]\u001b[A\nval @ step 2000:  87%|████████▋ | 20/23 [00:03<00:00,  6.18it/s]\u001b[A\nval @ step 2000:  91%|█████████▏| 21/23 [00:03<00:00,  6.23it/s]\u001b[A\nval @ step 2000: 100%|██████████| 23/23 [00:03<00:00,  6.35it/s]\u001b[A\nEpoch 12 [train]:  76%|███████▌  | 129/170 [01:04<00:20,  2.00it/s, loss=0.00298]","output_type":"stream"},{"name":"stdout","text":"\nStep 2000: val_loss = 0.0368, val_UAR = 0.6533\n  No UAR improvement for 10 eval(s).\n\nEarly stopping: no UAR improvement for 10 evals.\nBest step: 1000, best val UAR: 0.6755\nBest model weights saved to: /kaggle/working/language_fluencybank.pt\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!python /kaggle/input/test-code/test.py --metadata_path /kaggle/input/dataset-split/test_metadata.csv \\\n    --word_dir /kaggle/input/fluencybank-dataset/FluencyBank/csvs/csvs \\\n    --weights_path /kaggle/working/language_fluencybank.pt \\\n    --batch_size 16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T05:49:52.312153Z","iopub.execute_input":"2025-11-15T05:49:52.312518Z","iopub.status.idle":"2025-11-15T05:50:12.335616Z","shell.execute_reply.started":"2025-11-15T05:49:52.312479Z","shell.execute_reply":"2025-11-15T05:50:12.334606Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"2025-11-15 05:49:58.414413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763185798.440087     182 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763185798.447760     182 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nLoading weights from: /kaggle/working/language_fluencybank.pt\nEvaluating: 100%|███████████████████████████████| 23/23 [00:04<00:00,  5.18it/s]\n\n=== Evaluation Results ===\nAverage BCEWithLogits loss: 0.0398\n\nFP: precision=0.9930, recall=1.0000, f1=0.9965, support_pos=142\nRP: precision=0.8976, recall=0.9293, f1=0.9132, support_pos=396\nRV: precision=0.5798, recall=0.4233, f1=0.4894, support_pos=163\nRS: precision=0.0000, recall=0.0000, f1=0.0000, support_pos=0\nPW: precision=0.9393, recall=0.9263, f1=0.9327, support_pos=217\nND: precision=0.9819, recall=0.9885, f1=0.9852, support_pos=4331\n\nMacro averages (5 disfluencies + ND):\n  macro recall = 0.7112\n  macro F1     = 0.7195\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install -q gdown torchsummary huggingface_hub captum","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T05:58:51.438968Z","iopub.execute_input":"2025-11-15T05:58:51.439322Z","iopub.status.idle":"2025-11-15T06:00:08.712074Z","shell.execute_reply.started":"2025-11-15T05:58:51.439299Z","shell.execute_reply":"2025-11-15T06:00:08.710830Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from huggingface_hub import HfApi, login, create_repo, hf_hub_download\nfrom kaggle_secrets import UserSecretsClient\n# -------------------------\n# Upload the best model to huggingface\n# -------------------------\n# Get token and login\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(token=hf_token)\nprint(\"✅ Logged in to Hugging Face\")\n\n# Create the repository first (only needed once)\nrepo_id = \"HosseinRanjbar/disfluency_detection\"\ntry:\n    create_repo(\n        repo_id=repo_id,\n        token=hf_token,\n        private=False,  # Set to True if you want a private repo\n        repo_type=\"model\"\n    )\n    print(f\"✅ Repository created: {repo_id}\")\nexcept Exception as e:\n    print(f\"ℹ️  Repository might already exist: {e}\")\n\n# Save model (uncomment if not already saved)\nlocal_path = \"/kaggle/working/language_fluencybank.pt\"\n# torch.save(model.state_dict(), local_path)\n\n# Verify file exists\nif not os.path.exists(local_path):\n    raise FileNotFoundError(f\"Model file not found at: {local_path}\")\nelse:\n    file_size = os.path.getsize(local_path) / (1024 * 1024)  # MB\n    print(f\"✅ Model file found: {file_size:.2f} MB\")\n\n# Upload to Hugging Face\nprint(\"📤 Uploading to Hugging Face...\")\napi = HfApi()\napi.upload_file(\n    path_or_fileobj=local_path,\n    path_in_repo=\"language_model_fluencybank.pth\",\n    repo_id=repo_id,\n    repo_type=\"model\",\n    token=hf_token\n)\n\nprint(\"✅ Model uploaded to Hugging Face Hub!\")\nprint(f\"🔗 Access at: https://huggingface.co/{repo_id}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T06:01:48.218123Z","iopub.execute_input":"2025-11-15T06:01:48.218868Z","iopub.status.idle":"2025-11-15T06:02:05.022178Z","shell.execute_reply.started":"2025-11-15T06:01:48.218842Z","shell.execute_reply":"2025-11-15T06:02:05.021316Z"}},"outputs":[{"name":"stdout","text":"✅ Logged in to Hugging Face\nℹ️  Repository might already exist: 409 Client Error: Conflict for url: https://huggingface.co/api/repos/create (Request ID: Root=1-6918174c-46584adc0ea66b9a1953e00c;919a1f27-030d-424a-bafc-a1c4ebd940c3)\n\nYou already created this model repo: HosseinRanjbar/disfluency_detection\n✅ Model file found: 415.48 MB\n📤 Uploading to Hugging Face...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"951c79cddc1b4884a05a8c47259a8bf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd5a6e2207de4edb81f8fb30f18d221a"}},"metadata":{}},{"name":"stdout","text":"✅ Model uploaded to Hugging Face Hub!\n🔗 Access at: https://huggingface.co/HosseinRanjbar/disfluency_detection\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}